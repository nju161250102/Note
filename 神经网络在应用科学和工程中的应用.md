# 神经网络在应用科学和工程中的应用
#### ——从基本原理到复杂的模式识别
**Neural Networks for Applied Science and Engineering - From Fundamentals to Complex Pattern Recognition**

### Chapter2 神经网络基础和线性数据分析模型
#### 2.2 神经网络及其能力
神经网络是相互连接的神经元的集合。神经元是在一个网络里完成局部数据处理的最基本的数据单元。这些神经元逐步从它们的环境中学习，在复杂的数据里捕获线性和非线性的趋势。  

适合神经网络完成的任务：  
* 数据分类：指定数据属于哪一类（线性、非线性、联合体、多种类）
* 信息分类：指定时间序列属于哪一类（识别种类、识别异常）
* 无监督聚类：在数据中发现未知聚类
* 预测：预报时间序列的下一个结果

常见的神经网络类型：  
* 单层感知器：线性分类器
* 线性神经元：线性预报器/分类器
* 多层感知器：非线性预报器/分类器
* 竞争网络：无监督分类器
* SOM：无监督聚类/拓扑展示
* 循环pet网：时间序列预测

#### 2.5 神经元模型和学习策略
学习分类：  
* 无监督学习（竞争学习）：在没有外界作用时对自己进行正确响应的一种网络学习。  
* 有监督学习：对每一个指导学习过程的输入模式采用一个外部作用。包括强制学习、加强学习、误差校正学习。  

学习策略：  
* Hebbian学习：  
  如果x激励y（即向同一方向移动），他们之间的连接强度将得到加强。因此，权值的改变与x和y成比例。  
* 利用delta规则的学习： 
  使用平方误差作为误差指示，权值的改变与误差梯度的负值成比例。遍历学习：每个输入模式之后立即调整权值。批量学习：所有的输入模式被处理后从平均的意义上调整权值，即均方误差MSE。  
  
|神经元模型|激活函数|学习策略（即如何调整权值）|
|:---|:---|:---|
|感知器|阈值函数|Hebbian学习|
|线性神经元|线性函数|delta规则|

### 3 用于非线性识别的神经网络
#### 3.2 非线性神经元
神经元激励函数：  
* S型函数：对数激励函数、双曲正切函数、反正切函数
* 高斯函数、高斯补函数
* 正弦函数  

#### 3.3 单输入多层非线性网络
当通过使用一个单一的神经元去近似复杂的期望函数时，神经网络的能力可以通过增加并行动作的更多神经元得到提高。这说明MLP网络具有非线性处理的能力，可以用任意期望的精度去逼近任意的函数。  
神经元通过局部处理数据而全局互相影响产生输出，在不同的输入空间变得活跃以产生所需要的强度或者平衡一个持续的趋势。  

#### 3.4 两输入的多层感知器网络
是单输入多层非线性网络在高维的推广。  

### 4 神经网络对非线性模式的学习
#### 4.4 BP学习
使用链式法则来找到所有的误差导数。因此跟踪输入到输出的相关链就可以获得误差导数。  
批量学习：相对于整个训练集的全局误差以一个平均意义逐步下降，类似于前面的delta规则。  
学习率和权值更新的影响：高学习率导致结果振荡而达不到最小值；权值增加过大可能会导致学习中断。  
动量法：提供了在学习期间达到最优权值的稳定性。将过去的权值变化的平均值附加到每一次的新权值增加量上（由一个递推的表达式来完成）。可以用于在线学习中减少不同输入模式间的误差振动。  

#### 4.5 delta-bar-delta学习方法
对不同的权值有着不同的学习率：误差变化方向与最近变化的方向相比，一致则增加，相反则减少。优势在于学习可以很快地发生，不需要通过反复试验寻找最优参数。  

#### 4.6 最速下降法
学习率在每一步都会倍增，产生一个权值的预更新。如果MSE没有减小，则学习率减半继续训练，直到MSE减小时才进行权值调整。  

#### 4.7 误差最小和权值最优的二阶方法
* QiuckProp
* 高斯-牛顿方法
* LM方法  

### 5 从数据中抽取可靠模式的神经网络模型的实现
低灵活性的模型不能捕获数据的特征，高灵活性的模型影响对未知数据的泛化能力。充分训练的模型能严格拟合含有噪声的数据，但是更远离产生数据的实际模式。最简单的策略是通过穷举搜索反复试验寻找神经元的最优数目。  

#### 5.3.1 及早停止法  
验证数据集误差最小处是最优权值，产生使偏差-方差折中的最好的模型。大权值是产生过拟合的原因，及早停止法通过阻止权值增长超过泛化点来阻止过拟合。  

#### 5.3.2 正规化法
增加一个调节项，限制网络的灵活性。好的泛化参数可以更快找到最优权值，泛化参数太大又会限制权值的增长。  

#### 5.4 通过修建减少网络结构的复杂性
最优脑部损伤OBD：修剪不显著的权值后重新训练网络。  
基于网络灵敏度方差的网络修剪  

### 6 数据探测、维数约简和特征提取
#### 6.2 数据可视化
散点图和柱状图的相关性：对角柱状图表示独立变量的分布，非对角散点图表示独立变量之间如何关联。  
并行可视化：并行点数据与它们之间的相互关系。  
多维数据到二维平面的映射。  

### 9 神经网络在时间序列预测中的作用
#### 9.1 概述
后续输出可以与当前输出线性关联，也可以是非线性关联。时空模型既合成变量的时间滞后，也包含了其他有影响的变量。  

#### 9.2 应用统计模型和神经网络模型进行时间序列线性预测
下一时刻的观测值和过去观测值1-p时刻的滞后，误差值1-q时刻的滞后线性相关。  
使用相关变量、前面时间段数值训练线性模型，均方误差作为损失函数。  
随着预测范围增加，预测结果可能会变差。  

#### 9.3 用于非线性时间序列预测的神经网络
聚焦时间滞后前馈网络：使用短期记忆过滤器作为对静态前馈网络。  
短期记忆过滤器：具有扩展至滞后长度的短期记忆。  
时空时间滞后网络：过滤对每一个空间维度的短期记忆响应。
性能评价：RMSE、MAE
动态驱动递归网络：将序列的自相关结构增量式地建入模型内部。  
